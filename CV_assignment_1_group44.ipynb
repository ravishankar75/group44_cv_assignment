{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravishankar75/group44_cv_assignment/blob/main/CV_assignment_1_group44.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bda93ba",
      "metadata": {
        "id": "9bda93ba"
      },
      "source": [
        "## Group 44\n",
        "\n",
        "## Group Member Names:\n",
        "1. SAKTHI R (2023aa05940)\n",
        "2. ROBERTSEKAR R (2023aa05823)\n",
        "3. RAVISHANKAR R (2023aa05171)\n",
        "4. KRISHNAKUMAR C (2023aa05273)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Link: https://drive.google.com/file/d/18ivVD85YKQqPH0Qhe2Ou10hjuPl-vWxA/view?usp=sharing\n",
        "\n",
        "\n",
        "Choose any 1 dataset of your choice to perform the assignment."
      ],
      "metadata": {
        "id": "nxkuZrLQN7lH"
      },
      "id": "nxkuZrLQN7lH"
    },
    {
      "cell_type": "markdown",
      "id": "bec56339",
      "metadata": {
        "id": "bec56339"
      },
      "source": [
        "# 1. Import the required libraries -- Score: 0.5 Marks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46631608",
      "metadata": {
        "id": "46631608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5e05bf-c8ba-441a-bb0d-d544b210f196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3cc8e0cb",
      "metadata": {
        "id": "3cc8e0cb"
      },
      "source": [
        "# 2. Data Acquisition & Preparation -- Score: 1.5 Marks\n",
        "\n",
        "For the problem identified by you, students have to find the data source themselves from any data source.\n",
        "\n",
        "## 2.1 Data Acquisition -- Score: 0.5 Mark\n",
        "\n",
        "Code for converting the above downloaded data into a form suitable for DL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4b51d895",
      "metadata": {
        "id": "4b51d895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb500c12-e11c-4adb-a764-6a47df699100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decompression complete., Files extracted to /content/data\n",
            "Category: Forest, Number of Images: 2745\n",
            "Category: Streets, Number of Images: 501\n",
            "Category: Building, Number of Images: 501\n",
            "Category: Sea, Number of Images: 501\n",
            "Category: Mountains, Number of Images: 501\n",
            "Category: Glacier, Number of Images: 501\n"
          ]
        }
      ],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# Shared dataset link not working with gdown library due to permissions\n",
        "# The images have been downloaded and uploaded to Google drive(My).\n",
        "\n",
        "# The below steps necessary as on reconnect, google collab deletes the content folder\n",
        "\n",
        "colab_folder = \"/content\"  # Default working directory in Google Colab\n",
        "zip_file_name = \"/content/drive/MyDrive/scene_classification.zip\"\n",
        "\n",
        "\n",
        "# Decompress the zip file, using with instead of try/finally\n",
        "# check if data folder exists, if it exists then the dataset has been extracted\n",
        "\n",
        "if not os.path.exists(os.path.join(colab_folder, \"data\")):\n",
        "\n",
        "  print(\"Mounting Google Drive...\")\n",
        "  drive.mount('/content/drive') # Approve access for google desktop app\n",
        "\n",
        "  print(\"Decompressing the zip file...\")\n",
        "  with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "      extract_path = os.path.join(colab_folder, \"data\")\n",
        "      zip_ref.extractall(extract_path)\n",
        "\n",
        "print( f\"Decompression complete., Files extracted to {extract_path}\")\n",
        "\n",
        "# find the number of images for each category\n",
        "\n",
        "for category in os.listdir(os.path.join(colab_folder, \"data\", \"subset\")):\n",
        "  category_path = os.path.join(colab_folder, \"data\", \"subset\", category)\n",
        "  if not os.path.isdir(category_path):\n",
        "    continue\n",
        "  num_images = len(os.listdir(category_path))\n",
        "  print(f\"Category: {category}, Number of Images: {num_images}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to delete after completion\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (128, 128)  # Resize to 128x128\n",
        "NUM_IMAGES_PER_FOLDER = 5\n",
        "NUM_CLUSTERS = 3  # Number of clusters for K-means\n",
        "DATASET = []\n",
        "\n",
        "# Function to process an image\n",
        "def process_image(image_path):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        return None\n",
        "    # Resize image\n",
        "    resized_image = cv2.resize(image, IMAGE_SIZE)\n",
        "    # Reshape to a list of pixels\n",
        "    pixels = resized_image.reshape(-1, 3)\n",
        "\n",
        "    # covert to RGB image using cv2\n",
        "    # pixels = cv2.cvtColor(pixels, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Apply K-means clustering to find dominant colors\n",
        "    kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=0)\n",
        "    kmeans.fit(pixels)\n",
        "    # Extract RGB centers\n",
        "    dominant_colors = kmeans.cluster_centers_\n",
        "    return dominant_colors\n",
        "\n",
        "# Path to the base folder containing category subfolders\n",
        "base_folder = os.path.join(colab_folder, \"data\", \"subset\")\n",
        "\n",
        "# Iterate through category folders\n",
        "for category in os.listdir(base_folder):\n",
        "    category_path = os.path.join(base_folder, category)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue\n",
        "\n",
        "    # Process up to NUM_IMAGES_PER_FOLDER images in this category\n",
        "    image_count = 0\n",
        "    for image_file in os.listdir(category_path):\n",
        "        if image_count >= NUM_IMAGES_PER_FOLDER:\n",
        "            break\n",
        "\n",
        "        # Full path to image file\n",
        "        image_path = os.path.join(category_path, image_file)\n",
        "        if not os.path.isfile(image_path):\n",
        "            continue\n",
        "\n",
        "        # Process the image\n",
        "        dominant_colors = process_image(image_path)\n",
        "        if dominant_colors is not None:\n",
        "            # Append data to dataset\n",
        "            DATASET.append({\n",
        "                \"filename\": image_path,\n",
        "                \"label\": category,\n",
        "                \"dominant_colors\": dominant_colors.tolist()\n",
        "            })\n",
        "            image_count += 1\n",
        "\n",
        "# Convert dataset to a DataFrame\n",
        "df = pd.DataFrame(DATASET)\n",
        "\n",
        "# Save dataset to CSV\n",
        "df.to_csv(\"image_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Dataset created and saved to 'image_dataset.csv'\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIRncY-fB0jn",
        "outputId": "f0950a26-144b-4f99-e025-800f0f4e255b"
      },
      "id": "fIRncY-fB0jn",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created and saved to 'image_dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "812edb18",
      "metadata": {
        "id": "812edb18"
      },
      "source": [
        "## 2.2 Write your observations from the above.\n",
        "\n",
        "1. Size of the dataset\n",
        "2. Plot the distribution of the categories of the target / label.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "102e0e36",
      "metadata": {
        "id": "102e0e36"
      },
      "source": [
        "## 2.2 Data Preparation -- Score: 1.0 Marks\n",
        "\n",
        "Perform the data preprocessing that is required for the data that you have downloaded.\n",
        "\n",
        "\n",
        "This stage depends on the dataset that is used."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd14601",
      "metadata": {
        "id": "4cd14601"
      },
      "source": [
        "## 3.1 Split the data into training set and testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a74cd9c",
      "metadata": {
        "id": "1a74cd9c"
      },
      "outputs": [],
      "source": [
        "##---------Type the code below this line------------------##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3cec4fc",
      "metadata": {
        "id": "e3cec4fc"
      },
      "source": [
        "## 3.2 Feature Engineering -- Score: 3.5 Marks\n",
        "\n",
        "* Extract the features from the images and concatenate them to create a single for the every images.\n",
        "\n",
        "* You can choose from the feature processing techniques taught in the class : Low-level Vision: Histogram and Histogram equalization, Gray-scale transformation, Image Smoothing, Connected components in images.\n",
        "Mid-level Vision:  Edge Detection using Gradients, Sobel, Canny; Line detection using Hough transforms; Semantic information using RANSAC;Image region descriptor using SIFT; Use case: Pedestrian detection Using HoG and SIFT descriptors and SVM\n",
        "\n",
        "* Create multiple sets of features and store it in seperate dataframes so that you can later use it for training and comparing the models.\n",
        "\n",
        "* Normalize the DataFrame\n",
        "\n",
        "* Note : If the feature size is getting too large such that it is not fitting into the RAM of Colab or your system then you can either use PCA or resize the image to smaller dimenssion for reducing the numer of features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c77697",
      "metadata": {
        "id": "71c77697"
      },
      "outputs": [],
      "source": [
        "##---------Type the answer below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae0b5d2",
      "metadata": {
        "id": "3ae0b5d2"
      },
      "source": [
        "# 4. Model Building - Score: 2.0 Marks\n",
        "\n",
        "## 4.1 Model Building - Score: 1.5 Marks\n",
        "* Use any 1 classical machine learning algorithm such as : SVM , Xgboost etc. to train the model\n",
        "* Train the model on different kinds of feature combination dataframe you created in 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "868d7b27",
      "metadata": {
        "id": "868d7b27"
      },
      "outputs": [],
      "source": [
        "##---------Type the code below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "575f9e37",
      "metadata": {
        "id": "575f9e37"
      },
      "source": [
        "## 4.2 Validation matrix - Score: 0.5 Marks\n",
        "\n",
        "Print the model accuracy and F1 Score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad56d90",
      "metadata": {
        "id": "6ad56d90"
      },
      "outputs": [],
      "source": [
        "##---------Type the answer below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdbc82a1",
      "metadata": {
        "id": "bdbc82a1"
      },
      "source": [
        "# 5. Model Inference & Evaluation - Score: 1 Mark\n",
        "\n",
        "Plot any 5 random test images and their predicted and actual true labels using the model and feature set which gave you the best accuracy/F1 score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a85e9754",
      "metadata": {
        "id": "a85e9754"
      },
      "outputs": [],
      "source": [
        "##---------Type the code below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19bd0c56",
      "metadata": {
        "id": "19bd0c56"
      },
      "source": [
        "Justify your choice/inution of feature selection based on the performance of model such that why a particualr set have features might have performed well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89d2981",
      "metadata": {
        "id": "b89d2981"
      },
      "outputs": [],
      "source": [
        "##---------Type the answers below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Documentation, Study presentation and Code Quality -- Score: 1.5 Marks"
      ],
      "metadata": {
        "id": "rJBZ1ovpKgAR"
      },
      "id": "rJBZ1ovpKgAR"
    },
    {
      "cell_type": "markdown",
      "id": "RcDDQlfbZQ7E",
      "metadata": {
        "id": "RcDDQlfbZQ7E"
      },
      "source": [
        "### NOTE\n",
        "\n",
        "\n",
        "All Late Submissions will incur a <b>penalty of -2 marks </b>. So submit your assignments on time.\n",
        "\n",
        "Good Luck"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}